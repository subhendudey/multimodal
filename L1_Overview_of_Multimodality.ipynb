{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a97609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q accelerate torch\n",
    "# !pip install -U scikit-learn\n",
    "# !pip install umap-learn\n",
    "# !pip install tqdm\n",
    "# !pip install python-mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e00cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6804343f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnist_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m pio\u001b[38;5;241m.\u001b[39mrenderers\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miframe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Import our data class which will organize MNIST and provide anchor, positive and negative samples.\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmnist_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MNISTDataset\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mnist_dataset'"
     ]
    }
   ],
   "source": [
    "# Import neural network training libraries\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import basic computation libraries along with data visualization and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import umap.plot\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "# Import our data class which will organize MNIST and provide anchor, positive and negative samples.\n",
    "from mnist_dataset import MNISTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from csv\n",
    "data = pd.read_csv('digit-recognizer/train.csv')\n",
    "val_count = 1000\n",
    "# common transformation for both val and train\n",
    "default_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "# Split data into val and train\n",
    "dataset = MNISTDataset(data.iloc[:-val_count], default_transform)\n",
    "val_dataset = MNISTDataset(data.iloc[-val_count:], default_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ac1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataloaders\n",
    "trainLoader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=16, # feel free to modify this value\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")\n",
    "\n",
    "valLoader = DataLoader(val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b017d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images with labels\n",
    "def show_images(images, title=''):\n",
    "    num_images = len(images)\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(9, 3))\n",
    "    for i in range(num_images):\n",
    "        img = np.squeeze(images[i])\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize some examples\n",
    "for batch_idx, (anchor_images, contrastive_images, distances, labels) in enumerate(trainLoader):\n",
    "    # Convert tensors to numpy arrays\n",
    "    anchor_images = anchor_images.numpy()\n",
    "    contrastive_images = contrastive_images.numpy()\n",
    "    labels = labels.numpy()\n",
    "    \n",
    "    # Display some samples from the batch\n",
    "    show_images(anchor_images[:4], title='Anchor Image')\n",
    "    show_images(contrastive_images[:4], title='+/- Example')\n",
    "    \n",
    "    # Break after displaying one batch for demonstration\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74616824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a neural network architecture with two convolution layers and two fully connected layers\n",
    "# Input to the network is an MNIST image and Output is a 64 dimensional representation. \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d((2, 2), stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 64),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # x: d * 32 * 12 * 12\n",
    "        x = self.conv2(x) # x: d * 64 * 4  * 4 \n",
    "        x = x.view(x.size(0), -1) # x: d * (64*4*4)\n",
    "        x = self.linear1(x) # x: d * 64\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c58da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ideal distance metric for a positive sample is set to 1, for a negative sample it is set to 0      \n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.similarity = nn.CosineSimilarity(dim=-1, eps=1e-7)\n",
    "\n",
    "    def forward(self, anchor, contrastive, distance):\n",
    "        # use cosine similarity from torch to get score\n",
    "        score = self.similarity(anchor, contrastive)\n",
    "        # after cosine apply MSE between distance and score\n",
    "        return nn.MSELoss()(score, distance) #Ensures that the calculated score is close to the ideal distance (1 or 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    \n",
    "net = net.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7b57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training configuration\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "loss_function = ContrastiveLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a directory to save the checkpoints\n",
    "checkpoint_dir = 'checkpoints/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epoch_count=10):#\n",
    "    net = Network()\n",
    "    lrs = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epoch_count):\n",
    "        epoch_loss = 0\n",
    "        batches=0\n",
    "        print('epoch -', epoch)\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        print('learning rate', lrs[-1])\n",
    "    \n",
    "        for anchor, contrastive, distance, label in tqdm(trainLoader):\n",
    "            batches += 1\n",
    "            optimizer.zero_grad()\n",
    "            anchor_out = net(anchor.to(device))\n",
    "            contrastive_out = net(contrastive.to(device))\n",
    "            distance = distance.to(torch.float32).to(device)\n",
    "            loss = loss_function(anchor_out, contrastive_out, distance)\n",
    "            epoch_loss += loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(epoch_loss.cpu().detach().numpy() / batches)\n",
    "        scheduler.step()\n",
    "        print('epoch_loss', losses[-1])\n",
    "    \n",
    "        # Save a checkpoint of the model\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch}.pt')\n",
    "        torch.save(net.state_dict(), checkpoint_path)\n",
    "\n",
    "    return {\n",
    "        \"net\": net,\n",
    "        \"losses\": losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6aa0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint():\n",
    "    checkpoint = torch.load('checkpoints/model_epoch_99.pt')\n",
    "    \n",
    "    net = Network()\n",
    "    net.load_state_dict(checkpoint)\n",
    "    net.eval()\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf572e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = False # set to True to run train the model\n",
    "\n",
    "if train:\n",
    "    training_result = train_model()\n",
    "    model = training_result[\"net\"]\n",
    "else:\n",
    "    model = load_model_from_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1088606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "if train:\n",
    "    # show loss curve from your training.\n",
    "    plt.plot(training_result[\"losses\"])\n",
    "    plt.show()\n",
    "else:\n",
    "    # If you are loading a checkpoint instead of training the model (train = False),\n",
    "    # the following line will show a pre-saved loss curve from the checkpoint data.\n",
    "    display(Image(filename=\"images/loss-curve.png\", height=600, width=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for anchor, _, _, label in tqdm(trainLoader):\n",
    "        output = model(anchor.to(device))\n",
    "        encoded_data.extend(output.cpu().numpy())\n",
    "        labels.extend(label.cpu().numpy())\n",
    "\n",
    "encoded_data = np.array(encoded_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5afb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensionality of data from 64d -> 3d to make it easier to visualize!\n",
    "pca = PCA(n_components=3)\n",
    "encoded_data_3d = pca.fit_transform(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec11f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = go.Scatter3d(\n",
    "    x=encoded_data_3d[:, 0],\n",
    "    y=encoded_data_3d[:, 1],\n",
    "    z=encoded_data_3d[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=4, color=labels, colorscale='Viridis', opacity=0.8),\n",
    "    text=labels, \n",
    "    hoverinfo='text',\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    title=\"MNIST Dataset - Encoded and PCA Reduced 3D Scatter Plot\",\n",
    "    scene=dict(\n",
    "        xaxis=dict(title=\"PC1\"),\n",
    "        yaxis=dict(title=\"PC2\"),\n",
    "        zaxis=dict(title=\"PC3\"),\n",
    "    ),\n",
    "    width=1000, \n",
    "    height=750,\n",
    ")\n",
    "\n",
    "# Create figure and add scatter plot\n",
    "fig = go.Figure(data=[scatter], layout=layout)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = umap.UMAP(random_state=42, metric='cosine').fit(encoded_data)\n",
    "umap.plot.points(mapper, labels=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f5432",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = umap.UMAP(random_state=42).fit(encoded_data) \n",
    "umap.plot.points(mapper, labels=labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431665cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it to see the training!\n",
    "from IPython.display import Video\n",
    "Video(\"contrastive_Training_100.mp4\", height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9809838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e3a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9e8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
